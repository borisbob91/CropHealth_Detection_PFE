{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Notebook 1 : Setup Environment\n",
        "CropHealth Detection - Pr√©paration de l'environnement Google Colab"
      ],
      "metadata": {
        "id": "VdlIX91zPmoP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cellule 1 : V√©rifier GPU"
      ],
      "metadata": {
        "id": "V2Ifn1Q1PyE4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-jSaB-2BPjuA",
        "outputId": "42eee234-9e7a-4a94-fa37-168820593797"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "üîß CONFIGURATION GPU\n",
            "======================================================================\n",
            "‚úÖ GPU Disponible\n",
            "   ‚Ä¢ Mod√®le: Tesla T4\n",
            "   ‚Ä¢ M√©moire: 15.8 GB\n",
            "   ‚Ä¢ CUDA Version: 12.6\n",
            "   ‚Ä¢ PyTorch Version: 2.8.0+cu126\n",
            "======================================================================\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import sys\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"üîß CONFIGURATION GPU\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# GPU Check\n",
        "if torch.cuda.is_available():\n",
        "    gpu_name = torch.cuda.get_device_name(0)\n",
        "    gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
        "    cuda_version = torch.version.cuda\n",
        "\n",
        "    print(f\"‚úÖ GPU Disponible\")\n",
        "    print(f\"   ‚Ä¢ Mod√®le: {gpu_name}\")\n",
        "    print(f\"   ‚Ä¢ M√©moire: {gpu_memory:.1f} GB\")\n",
        "    print(f\"   ‚Ä¢ CUDA Version: {cuda_version}\")\n",
        "    print(f\"   ‚Ä¢ PyTorch Version: {torch.__version__}\")\n",
        "else:\n",
        "    print(\"‚ùå Pas de GPU d√©tect√© !\")\n",
        "    print(\"üí° Activer GPU: Runtime > Change runtime type > GPU (T4)\")\n",
        "    sys.exit(1)\n",
        "\n",
        "print(\"=\"*70)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cellule 2 : Cloner le repository"
      ],
      "metadata": {
        "id": "qh62y-L4QOEZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"üì¶ CLONAGE DU PROJET\")\n",
        "print(\"=\"*70 + \"\\n\")\n",
        "\n",
        "# Supprimer ancien clone si existe\n",
        "if Path('CropHealth_Detection_PFE').exists():\n",
        "    print(\"‚ö†Ô∏è  Projet d√©j√† clon√©, suppression...\")\n",
        "    !rm -rf CropHealth_Detection_PFE\n",
        "\n",
        "# Cloner\n",
        "!git clone https://github.com/borisbob91/CropHealth_Detection_PFE.git\n",
        "\n",
        "# Aller dans le dossier\n",
        "%cd CropHealth_Detection_PFE\n",
        "\n",
        "# V√©rifier structure\n",
        "print(\"\\n‚úÖ Projet clon√© !\")\n",
        "print(\"\\nüìÅ Structure du projet:\")\n",
        "!ls -la"
      ],
      "metadata": {
        "id": "pH40VSsYQQxJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e7284905-e750-4fc6-a991-7d64e8c535f3"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "üì¶ CLONAGE DU PROJET\n",
            "======================================================================\n",
            "\n",
            "Cloning into 'CropHealth_Detection_PFE'...\n",
            "remote: Enumerating objects: 83, done.\u001b[K\n",
            "remote: Counting objects: 100% (83/83), done.\u001b[K\n",
            "remote: Compressing objects: 100% (68/68), done.\u001b[K\n",
            "remote: Total 83 (delta 18), reused 73 (delta 12), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (83/83), 333.95 KiB | 1.83 MiB/s, done.\n",
            "Resolving deltas: 100% (18/18), done.\n",
            "/content/CropHealth_Detection_PFE\n",
            "\n",
            "‚úÖ Projet clon√© !\n",
            "\n",
            "üìÅ Structure du projet:\n",
            "total 208\n",
            "drwxr-xr-x 12 root root  4096 Nov 20 02:22 .\n",
            "drwxr-xr-x  1 root root  4096 Nov 20 02:22 ..\n",
            "drwxr-xr-x  2 root root  4096 Nov 20 02:22 configs\n",
            "drwxr-xr-x  2 root root  4096 Nov 20 02:22 datasets\n",
            "-rw-r--r--  1 root root 27173 Nov 20 02:22 evaluate_models.py\n",
            "drwxr-xr-x  2 root root  4096 Nov 20 02:22 exports\n",
            "drwxr-xr-x  8 root root  4096 Nov 20 02:22 .git\n",
            "-rw-r--r--  1 root root    66 Nov 20 02:22 .gitattributes\n",
            "-rw-r--r--  1 root root   181 Nov 20 02:22 .gitignore\n",
            "drwxr-xr-x  3 root root  4096 Nov 20 02:22 .idea\n",
            "-rw-r--r--  1 root root  1092 Nov 20 02:22 LICENSE\n",
            "-rw-r--r--  1 root root 13419 Nov 20 02:22 model_predict.py\n",
            "drwxr-xr-x  2 root root  4096 Nov 20 02:22 models\n",
            "drwxr-xr-x  2 root root  4096 Nov 20 02:22 notebooks\n",
            "-rw-r--r--  1 root root 13796 Nov 20 02:22 README.md\n",
            "-rw-r--r--  1 root root  1343 Nov 20 02:22 requirements.txt\n",
            "drwxr-xr-x  2 root root  4096 Nov 20 02:22 script\n",
            "-rw-r--r--  1 root root  4723 Nov 20 02:22 setup_notebook.py\n",
            "-rw-r--r--  1 root root  1227 Nov 20 02:22 starter.ipynb\n",
            "-rw-r--r--  1 root root 47922 Nov 20 02:22 start.ipynb\n",
            "drwxr-xr-x  2 root root  4096 Nov 20 02:22 trainers\n",
            "-rw-r--r--  1 root root  8220 Nov 20 02:22 train.py\n",
            "-rw-r--r--  1 root root  3194 Nov 20 02:22 train_yolo.py\n",
            "drwxr-xr-x  2 root root  4096 Nov 20 02:22 utils\n",
            "-rw-r--r--  1 root root  7331 Nov 20 02:22 yolo_predict.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üìå Cellule 3 : Installer les d√©pendances"
      ],
      "metadata": {
        "id": "3Nt5XZCtQWwT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"üì¶ INSTALLATION DES D√âPENDANCES\")\n",
        "print(\"=\"*70 + \"\\n\")\n",
        "\n",
        "# Installation silencieuse\n",
        "print(\"‚è≥ Installation en cours (2-3 minutes)...\")\n",
        "\n",
        "# Core dependencies\n",
        "!pip install -q torch torchvision torchmetrics\n",
        "\n",
        "# Detection frameworks\n",
        "!pip install -q ultralytics effdet timm\n",
        "\n",
        "# Data & Augmentation\n",
        "!pip install -q albumentations opencv-python\n",
        "\n",
        "# Metrics & Evaluation\n",
        "!pip install -q pycocotools scikit-learn\n",
        "\n",
        "# Visualization\n",
        "!pip install -q matplotlib seaborn tensorboard\n",
        "\n",
        "# Model analysis\n",
        "!pip install -q thop torchinfo\n",
        "\n",
        "print(\"\\n‚úÖ D√©pendances install√©es !\\n\")\n",
        "\n",
        "# V√©rifier versions\n",
        "import torch\n",
        "import torchvision\n",
        "import ultralytics\n",
        "import albumentations\n",
        "\n",
        "print(\"üìã Versions install√©es:\")\n",
        "print(f\"   ‚Ä¢ PyTorch: {torch.__version__}\")\n",
        "print(f\"   ‚Ä¢ TorchVision: {torchvision.__version__}\")\n",
        "print(f\"   ‚Ä¢ Ultralytics: {ultralytics.__version__}\")\n",
        "print(f\"   ‚Ä¢ Albumentations: {albumentations.__version__}\")"
      ],
      "metadata": {
        "id": "mw4QdadbQbGo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a54ae8dc-78e0-48a7-f691-9ac254b91e37"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "üì¶ INSTALLATION DES D√âPENDANCES\n",
            "======================================================================\n",
            "\n",
            "‚è≥ Installation en cours (2-3 minutes)...\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m983.2/983.2 kB\u001b[0m \u001b[31m30.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m34.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m112.5/112.5 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\n",
            "‚úÖ D√©pendances install√©es !\n",
            "\n",
            "Creating new Ultralytics Settings v0.0.6 file ‚úÖ \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n",
            "üìã Versions install√©es:\n",
            "   ‚Ä¢ PyTorch: 2.8.0+cu126\n",
            "   ‚Ä¢ TorchVision: 0.23.0+cu126\n",
            "   ‚Ä¢ Ultralytics: 8.3.229\n",
            "   ‚Ä¢ Albumentations: 2.0.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cellule 4 : Monter Google Drive"
      ],
      "metadata": {
        "id": "hT675hHFQnaP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"üíæ MONTAGE GOOGLE DRIVE\")\n",
        "print(\"=\"*70 + \"\\n\")\n",
        "\n",
        "# Monter Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "print(\"\\n‚úÖ Google Drive mont√© !\")\n",
        "print(f\"üìÅ Accessible via: /content/drive/MyDrive/\")"
      ],
      "metadata": {
        "id": "uEEZcwibQrW5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üìå Cellule 5 : Uploader et pr√©parer le dataset"
      ],
      "metadata": {
        "id": "UCFOmr0wQ2uL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "import zipfile\n",
        "import shutil\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"üì§ PR√âPARATION DU DATASET\")\n",
        "print(\"=\"*70 + \"\\n\")\n",
        "\n",
        "# Option A : Depuis Google Drive\n",
        "use_drive = True  # Mettre False pour uploader manuellement\n",
        "\n",
        "if use_drive:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "    print(\"üìÅ Utilisation du dataset depuis Google Drive...\")\n",
        "\n",
        "    # chemin selon votre structure Drive\n",
        "    drive_dataset_path = \"/content/drive/MyDrive/CropHealth\"\n",
        "    !unzip \"/content/drive/MyDrive/CropHealth/pascal_voc_original.zip\" -d \"/content/drive/MyDrive/CropHealth/pascal_voc_original\"\n",
        "\n",
        "    if Path(drive_dataset_path).exists():\n",
        "        # Cr√©er lien symbolique\n",
        "        !ln -sf {drive_dataset_path} data/pascal_voc_original\n",
        "        print(f\"‚úÖ Dataset li√© depuis: {drive_dataset_path}\")\n",
        "    else:\n",
        "        print(f\"‚ùå Dataset non trouv√© dans Drive: {drive_dataset_path}\")\n",
        "        print(\"üí° Mettre use_drive=False pour upload manuel\")\n",
        "else:\n",
        "    # Option B : Upload manuel\n",
        "    print(\"üì§ Upload votre dataset ZIP (Pascal VOC format)...\")\n",
        "    uploaded = files.upload()\n",
        "\n",
        "    for filename in uploaded.keys():\n",
        "        print(f\"\\nüì¶ Extraction de {filename}...\")\n",
        "\n",
        "        with zipfile.ZipFile(filename, 'r') as zip_ref:\n",
        "            zip_ref.extractall('data/pascal_voc')\n",
        "\n",
        "        print(f\"‚úÖ Extraction termin√©e !\")\n",
        "\n",
        "# V√©rifier structure\n",
        "print(\"\\nüìã V√©rification de la structure...\")\n",
        "!tree data/pascal_voc_orignal -L 2 -d"
      ],
      "metadata": {
        "id": "x9Ptq6qjQ3TF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# augmentation du dataset depuis pascal_voc"
      ],
      "metadata": {
        "id": "_zKuo3QpFvmG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"üîÑ Augmenation PASCAL VOC\")\n",
        "print(\"=\"*70 + \"\\n\")\n",
        "\n",
        "# Convertir VOC ‚Üí YOLO\n",
        "!python script/augment_pascal_voc.py -i data/pascal_voc_original/train -o data/pascal_voc/train -t train -b True\n",
        "!python script/augment_pascal_voc.py -i data/pascal_voc_original/val -o data/pascal_voc/val -t val -b True\n",
        "!python script/augment_pascal_voc.py -i data/pascal_voc_original/test -o data/pascal_voc/test -t val -b True\n",
        "\n",
        "print(\"\\n‚úÖ Conversion YOLO termin√©e !\")"
      ],
      "metadata": {
        "id": "LVj9WFX_F1GC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Visualiser les donn√©es augment√©"
      ],
      "metadata": {
        "id": "mrAxMLSzRDwv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"üîÑVisualisation apres Augmenation PASCAL VOC\")\n",
        "print(\"=\"*70 + \"\\n\")\n",
        "\n",
        "!python /utils/pascal_viz.py -d data/pascal_voc/train -n 6\n",
        "print(\"\\n‚úÖ visualisation train termin√©e !\")\n",
        "!python /utils/pascal_viz.py -d data/pascal_voc/val -n 6\n",
        "print(\"\\n‚úÖ visualisation train termin√©e !\")\n",
        "!python /utils/pascal_viz.py -d data/pascal_voc/test -n 6\n",
        "print(\"\\n‚úÖ visualisation train termin√©e !\")"
      ],
      "metadata": {
        "id": "lKDDzPfnRJeN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "üìå Cellule 6 : Convertir Pascal VOC ‚Üí YOLO"
      ],
      "metadata": {
        "id": "SocIRDgSRZX1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"üîÑ CONVERSION PASCAL VOC ‚Üí YOLO\")\n",
        "print(\"=\"*70 + \"\\n\")\n",
        "\n",
        "# Convertir VOC ‚Üí YOLO\n",
        "!python utils/pascalvoc_to_yolo.py \\\n",
        "    --voc-root data/pascal_voc \\\n",
        "    --output data/yolo_crop \\\n",
        "    --format yolo\n",
        "\n",
        "print(\"\\n‚úÖ Conversion YOLO termin√©e !\")"
      ],
      "metadata": {
        "id": "wBeG_PqyRbC8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üìå Cellule 7 : Convertir Pascal VOC ‚Üí COCO"
      ],
      "metadata": {
        "id": "8WJ_68hLS-mH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"üîÑ CONVERSION PASCAL VOC ‚Üí COCO\")\n",
        "print(\"=\"*70 + \"\\n\")\n",
        "\n",
        "# Convertir VOC ‚Üí COCO (pour EfficientDet)\n",
        "!python utils/pascalvoc_to_yolo.py \\\n",
        "    --voc-root data/pascal_voc \\\n",
        "    --output data/coco_crop \\\n",
        "    --format coco\n",
        "\n",
        "print(\"\\n‚úÖ Conversion COCO termin√©e !\")"
      ],
      "metadata": {
        "id": "GhQQI9GuTFo4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "üìå Cellule 8 : V√©rifier les datasets"
      ],
      "metadata": {
        "id": "0mV8eXbHTftI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"üìä V√âRIFICATION DES DATASETS\")\n",
        "print(\"=\"*70 + \"\\n\")\n",
        "\n",
        "datasets_info = []\n",
        "\n",
        "# Pascal VOC\n",
        "for split in ['train', 'val', 'test']:\n",
        "    voc_imgs = Path(f'data/pascal_voc/{split}/images')\n",
        "    voc_anns = Path(f'data/pascal_voc/{split}/Annotations')\n",
        "\n",
        "    if voc_imgs.exists():\n",
        "        img_count = len(list(voc_imgs.glob('*.jpg')))\n",
        "        xml_count = len(list(voc_anns.glob('*.xml'))) if voc_anns.exists() else 0\n",
        "        datasets_info.append(['Pascal VOC', split, img_count, xml_count])\n",
        "\n",
        "# YOLO\n",
        "for split in ['train', 'val', 'test']:\n",
        "    yolo_imgs = Path(f'data/yolo_crop/{split}/images')\n",
        "    yolo_lbls = Path(f'data/yolo_crop/{split}/labels')\n",
        "\n",
        "    if yolo_imgs.exists():\n",
        "        img_count = len(list(yolo_imgs.glob('*.jpg')))\n",
        "        txt_count = len(list(yolo_lbls.glob('*.txt'))) if yolo_lbls.exists() else 0\n",
        "        datasets_info.append(['YOLO', split, img_count, txt_count])\n",
        "\n",
        "# COCO\n",
        "for split in ['train', 'val', 'test']:\n",
        "    coco_imgs = Path(f'data/coco_crop/{split}/images')\n",
        "    coco_json = Path(f'data/coco_crop/{split}/annotations.json')\n",
        "\n",
        "    if coco_imgs.exists():\n",
        "        img_count = len(list(coco_imgs.glob('*.jpg')))\n",
        "        json_exists = '‚úÖ' if coco_json.exists() else '‚ùå'\n",
        "        datasets_info.append(['COCO', split, img_count, json_exists])\n",
        "\n",
        "# Afficher tableau\n",
        "df = pd.DataFrame(datasets_info, columns=['Format', 'Split', 'Images', 'Annotations'])\n",
        "print(df.to_string(index=False))\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)"
      ],
      "metadata": {
        "id": "gFnrkOEdTgrC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "viz data"
      ],
      "metadata": {
        "id": "paNpKul_Zaw_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"üîÑ CONVERSION PASCAL VOC ‚Üí COCO\")\n",
        "print(\"=\"*70 + \"\\n\")\n",
        "\n",
        "# Convertir VOC ‚Üí COCO (pour EfficientDet)\n",
        "!python utils/pascalvoc_to_yolo.py \\\n",
        "    --voc-root data/pascal_voc \\\n",
        "    --output data/coco_crop \\\n",
        "    --format coco\n",
        "\n",
        "!python utils/yol_viz.py -d data/yolo_crop -n 6\n",
        "\n",
        "!python utils/pascal_viz.py -d data/pascal_voc -n 6\n",
        "\n",
        "print(\"\\n‚úÖ Conversion COCO termin√©e !\")"
      ],
      "metadata": {
        "id": "pM8nMvmyZaZY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üìå Cellule 9 : Cr√©er dossiers de sortie"
      ],
      "metadata": {
        "id": "sg-vmxI-T5lP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"üìÅ CR√âATION DES DOSSIERS DE SORTIE\")\n",
        "print(\"=\"*70 + \"\\n\")\n",
        "\n",
        "# Cr√©er structure\n",
        "output_dirs = [\n",
        "    'runs',\n",
        "    'predictions',\n",
        "    'evaluation_results',\n",
        "    'exports',\n",
        "]\n",
        "\n",
        "for dir_name in output_dirs:\n",
        "    Path(dir_name).mkdir(exist_ok=True)\n",
        "    print(f\"‚úÖ {dir_name}/\")\n",
        "\n",
        "print(\"\\n‚úÖ Dossiers cr√©√©s !\")"
      ],
      "metadata": {
        "id": "7A43iNffT7QW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "visualiser les donn√©es:"
      ],
      "metadata": {
        "id": "P6MGfAuEZOc8"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cU7RBIFmZRK3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cellule 10 : R√©sum√© de l'environnement"
      ],
      "metadata": {
        "id": "hG8WW-rvZIER"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"üìã R√âSUM√â DE L'ENVIRONNEMENT\")\n",
        "print(\"=\"*70 + \"\\n\")\n",
        "\n",
        "summary = {\n",
        "    \"GPU\": torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"None\",\n",
        "    \"CUDA\": torch.version.cuda if torch.cuda.is_available() else \"N/A\",\n",
        "    \"PyTorch\": torch.__version__,\n",
        "    \"Datasets\": {},\n",
        "    \"Projet\": \"CropHealth_Detection_PFE\",\n",
        "    \"Status\": \"‚úÖ Pr√™t pour le training\"\n",
        "}\n",
        "\n",
        "# Compter images\n",
        "for format_name in ['pascal_voc', 'yolo_crop', 'coco_crop']:\n",
        "    train_imgs = Path(f'data/{format_name}/train')\n",
        "    if train_imgs.exists():\n",
        "        if format_name == 'pascal_voc':\n",
        "            count = len(list((train_imgs / 'images').glob('*.jpg')))\n",
        "        else:\n",
        "            count = len(list((train_imgs / 'images').glob('*.jpg')))\n",
        "\n",
        "        summary[\"Datasets\"][format_name] = f\"{count} images\"\n",
        "\n",
        "# Afficher\n",
        "print(json.dumps(summary, indent=2, ensure_ascii=False))\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"‚úÖ ENVIRONNEMENT PR√äT !\")\n",
        "print(\"=\"*70)\n",
        "print(\"\\n‚û°Ô∏è  Passez au Notebook 2 : Training\")"
      ],
      "metadata": {
        "id": "D0SZW1c6ZIrp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}