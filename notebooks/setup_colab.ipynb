{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Notebook 1 : Setup Environment\n",
        "CropHealth Detection - Pr√©paration de l'environnement Google Colab"
      ],
      "metadata": {
        "id": "VdlIX91zPmoP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cellule 1 : V√©rifier GPU"
      ],
      "metadata": {
        "id": "V2Ifn1Q1PyE4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        },
        "id": "-jSaB-2BPjuA",
        "outputId": "eef89aa8-f0c7-4b4c-ed1b-74212772f09f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "üîß CONFIGURATION GPU\n",
            "======================================================================\n",
            "‚ùå Pas de GPU d√©tect√© !\n",
            "üí° Activer GPU: Runtime > Change runtime type > GPU (T4)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "SystemExit",
          "evalue": "1",
          "traceback": [
            "An exception has occurred, use %tb to see the full traceback.\n",
            "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/IPython/core/interactiveshell.py:3561: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
            "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import sys\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"üîß CONFIGURATION GPU\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# GPU Check\n",
        "if torch.cuda.is_available():\n",
        "    gpu_name = torch.cuda.get_device_name(0)\n",
        "    gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
        "    cuda_version = torch.version.cuda\n",
        "\n",
        "    print(f\"‚úÖ GPU Disponible\")\n",
        "    print(f\"   ‚Ä¢ Mod√®le: {gpu_name}\")\n",
        "    print(f\"   ‚Ä¢ M√©moire: {gpu_memory:.1f} GB\")\n",
        "    print(f\"   ‚Ä¢ CUDA Version: {cuda_version}\")\n",
        "    print(f\"   ‚Ä¢ PyTorch Version: {torch.__version__}\")\n",
        "else:\n",
        "    print(\"‚ùå Pas de GPU d√©tect√© !\")\n",
        "    print(\"üí° Activer GPU: Runtime > Change runtime type > GPU (T4)\")\n",
        "    sys.exit(1)\n",
        "\n",
        "print(\"=\"*70)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cellule 2 : Cloner le repository"
      ],
      "metadata": {
        "id": "qh62y-L4QOEZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"üì¶ CLONAGE DU PROJET\")\n",
        "print(\"=\"*70 + \"\\n\")\n",
        "\n",
        "# Supprimer ancien clone si existe\n",
        "if Path('CropHealth_Detection_PFE').exists():\n",
        "    print(\"‚ö†Ô∏è  Projet d√©j√† clon√©, suppression...\")\n",
        "    !rm -rf CropHealth_Detection_PFE\n",
        "\n",
        "# Cloner\n",
        "!git clone https://github.com/borisbob91/CropHealth_Detection_PFE.git\n",
        "\n",
        "# Aller dans le dossier\n",
        "%cd CropHealth_Detection_PFE\n",
        "\n",
        "# V√©rifier structure\n",
        "print(\"\\n‚úÖ Projet clon√© !\")\n",
        "print(\"\\nüìÅ Structure du projet:\")\n",
        "!ls -la"
      ],
      "metadata": {
        "id": "pH40VSsYQQxJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üìå Cellule 3 : Installer les d√©pendances"
      ],
      "metadata": {
        "id": "3Nt5XZCtQWwT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"üì¶ INSTALLATION DES D√âPENDANCES\")\n",
        "print(\"=\"*70 + \"\\n\")\n",
        "\n",
        "# Installation silencieuse\n",
        "print(\"‚è≥ Installation en cours (2-3 minutes)...\")\n",
        "\n",
        "# Core dependencies\n",
        "!pip install -q torch torchvision torchmetrics\n",
        "\n",
        "# Detection frameworks\n",
        "!pip install -q ultralytics effdet timm\n",
        "\n",
        "# Data & Augmentation\n",
        "!pip install -q albumentations opencv-python\n",
        "\n",
        "# Metrics & Evaluation\n",
        "!pip install -q pycocotools scikit-learn\n",
        "\n",
        "# Visualization\n",
        "!pip install -q matplotlib seaborn tensorboard\n",
        "\n",
        "# Model analysis\n",
        "!pip install -q thop torchinfo\n",
        "\n",
        "print(\"\\n‚úÖ D√©pendances install√©es !\\n\")\n",
        "\n",
        "# V√©rifier versions\n",
        "import torch\n",
        "import torchvision\n",
        "import ultralytics\n",
        "import albumentations\n",
        "\n",
        "print(\"üìã Versions install√©es:\")\n",
        "print(f\"   ‚Ä¢ PyTorch: {torch.__version__}\")\n",
        "print(f\"   ‚Ä¢ TorchVision: {torchvision.__version__}\")\n",
        "print(f\"   ‚Ä¢ Ultralytics: {ultralytics.__version__}\")\n",
        "print(f\"   ‚Ä¢ Albumentations: {albumentations.__version__}\")"
      ],
      "metadata": {
        "id": "mw4QdadbQbGo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cellule 4 : Monter Google Drive"
      ],
      "metadata": {
        "id": "hT675hHFQnaP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"üíæ MONTAGE GOOGLE DRIVE\")\n",
        "print(\"=\"*70 + \"\\n\")\n",
        "\n",
        "# Monter Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "print(\"\\n‚úÖ Google Drive mont√© !\")\n",
        "print(f\"üìÅ Accessible via: /content/drive/MyDrive/\")"
      ],
      "metadata": {
        "id": "uEEZcwibQrW5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üìå Cellule 5 : Uploader et pr√©parer le dataset"
      ],
      "metadata": {
        "id": "UCFOmr0wQ2uL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "import zipfile\n",
        "import shutil\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"üì§ PR√âPARATION DU DATASET\")\n",
        "print(\"=\"*70 + \"\\n\")\n",
        "\n",
        "# Option A : Depuis Google Drive\n",
        "use_drive = True  # Mettre False pour uploader manuellement\n",
        "\n",
        "if use_drive:\n",
        "    print(\"üìÅ Utilisation du dataset depuis Google Drive...\")\n",
        "\n",
        "    # Adapter ce chemin selon votre structure Drive\n",
        "    drive_dataset_path = \"/content/drive/MyDrive/CropHealth_Dataset\"\n",
        "\n",
        "    if Path(drive_dataset_path).exists():\n",
        "        # Cr√©er lien symbolique\n",
        "        !ln -sf {drive_dataset_path} data/pascal_voc\n",
        "        print(f\"‚úÖ Dataset li√© depuis: {drive_dataset_path}\")\n",
        "    else:\n",
        "        print(f\"‚ùå Dataset non trouv√© dans Drive: {drive_dataset_path}\")\n",
        "        print(\"üí° Mettre use_drive=False pour upload manuel\")\n",
        "\n",
        "else:\n",
        "    # Option B : Upload manuel\n",
        "    print(\"üì§ Upload votre dataset ZIP (Pascal VOC format)...\")\n",
        "    uploaded = files.upload()\n",
        "\n",
        "    for filename in uploaded.keys():\n",
        "        print(f\"\\nüì¶ Extraction de {filename}...\")\n",
        "\n",
        "        with zipfile.ZipFile(filename, 'r') as zip_ref:\n",
        "            zip_ref.extractall('data/pascal_voc')\n",
        "\n",
        "        print(f\"‚úÖ Extraction termin√©e !\")\n",
        "\n",
        "# V√©rifier structure\n",
        "print(\"\\nüìã V√©rification de la structure...\")\n",
        "!tree data/pascal_voc -L 2 -d"
      ],
      "metadata": {
        "id": "x9Ptq6qjQ3TF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "üìå Cellule 6 : Convertir Pascal VOC ‚Üí YOLO"
      ],
      "metadata": {
        "id": "SocIRDgSRZX1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"üîÑ CONVERSION PASCAL VOC ‚Üí YOLO\")\n",
        "print(\"=\"*70 + \"\\n\")\n",
        "\n",
        "# Convertir VOC ‚Üí YOLO\n",
        "!python utils/pascalvoc_to_yolo.py \\\n",
        "    --voc-root data/pascal_voc \\\n",
        "    --output data/yolo_crop \\\n",
        "    --format yolo\n",
        "\n",
        "print(\"\\n‚úÖ Conversion YOLO termin√©e !\")"
      ],
      "metadata": {
        "id": "wBeG_PqyRbC8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üìå Cellule 7 : Convertir Pascal VOC ‚Üí COCO"
      ],
      "metadata": {
        "id": "8WJ_68hLS-mH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"üîÑ CONVERSION PASCAL VOC ‚Üí COCO\")\n",
        "print(\"=\"*70 + \"\\n\")\n",
        "\n",
        "# Convertir VOC ‚Üí COCO (pour EfficientDet)\n",
        "!python utils/pascalvoc_to_yolo.py \\\n",
        "    --voc-root data/pascal_voc \\\n",
        "    --output data/coco_crop \\\n",
        "    --format coco\n",
        "\n",
        "print(\"\\n‚úÖ Conversion COCO termin√©e !\")"
      ],
      "metadata": {
        "id": "GhQQI9GuTFo4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "üìå Cellule 8 : V√©rifier les datasets"
      ],
      "metadata": {
        "id": "0mV8eXbHTftI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"üìä V√âRIFICATION DES DATASETS\")\n",
        "print(\"=\"*70 + \"\\n\")\n",
        "\n",
        "datasets_info = []\n",
        "\n",
        "# Pascal VOC\n",
        "for split in ['train', 'val', 'test']:\n",
        "    voc_imgs = Path(f'data/pascal_voc/{split}/images')\n",
        "    voc_anns = Path(f'data/pascal_voc/{split}/Annotations')\n",
        "\n",
        "    if voc_imgs.exists():\n",
        "        img_count = len(list(voc_imgs.glob('*.jpg')))\n",
        "        xml_count = len(list(voc_anns.glob('*.xml'))) if voc_anns.exists() else 0\n",
        "        datasets_info.append(['Pascal VOC', split, img_count, xml_count])\n",
        "\n",
        "# YOLO\n",
        "for split in ['train', 'val', 'test']:\n",
        "    yolo_imgs = Path(f'data/yolo_crop/{split}/images')\n",
        "    yolo_lbls = Path(f'data/yolo_crop/{split}/labels')\n",
        "\n",
        "    if yolo_imgs.exists():\n",
        "        img_count = len(list(yolo_imgs.glob('*.jpg')))\n",
        "        txt_count = len(list(yolo_lbls.glob('*.txt'))) if yolo_lbls.exists() else 0\n",
        "        datasets_info.append(['YOLO', split, img_count, txt_count])\n",
        "\n",
        "# COCO\n",
        "for split in ['train', 'val', 'test']:\n",
        "    coco_imgs = Path(f'data/coco_crop/{split}/images')\n",
        "    coco_json = Path(f'data/coco_crop/{split}/annotations.json')\n",
        "\n",
        "    if coco_imgs.exists():\n",
        "        img_count = len(list(coco_imgs.glob('*.jpg')))\n",
        "        json_exists = '‚úÖ' if coco_json.exists() else '‚ùå'\n",
        "        datasets_info.append(['COCO', split, img_count, json_exists])\n",
        "\n",
        "# Afficher tableau\n",
        "df = pd.DataFrame(datasets_info, columns=['Format', 'Split', 'Images', 'Annotations'])\n",
        "print(df.to_string(index=False))\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)"
      ],
      "metadata": {
        "id": "gFnrkOEdTgrC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "viz data"
      ],
      "metadata": {
        "id": "paNpKul_Zaw_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"üîÑ CONVERSION PASCAL VOC ‚Üí COCO\")\n",
        "print(\"=\"*70 + \"\\n\")\n",
        "\n",
        "# Convertir VOC ‚Üí COCO (pour EfficientDet)\n",
        "!python utils/pascalvoc_to_yolo.py \\\n",
        "    --voc-root data/pascal_voc \\\n",
        "    --output data/coco_crop \\\n",
        "    --format coco\n",
        "\n",
        "!python utils/yol_viz.py -d data/yolo_crop -n 6\n",
        "\n",
        "!python utils/pascal_viz.py -d data/pascal_voc -n 6\n",
        "\n",
        "print(\"\\n‚úÖ Conversion COCO termin√©e !\")"
      ],
      "metadata": {
        "id": "pM8nMvmyZaZY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üìå Cellule 9 : Cr√©er dossiers de sortie"
      ],
      "metadata": {
        "id": "sg-vmxI-T5lP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"üìÅ CR√âATION DES DOSSIERS DE SORTIE\")\n",
        "print(\"=\"*70 + \"\\n\")\n",
        "\n",
        "# Cr√©er structure\n",
        "output_dirs = [\n",
        "    'runs',\n",
        "    'predictions',\n",
        "    'evaluation_results',\n",
        "    'exports',\n",
        "]\n",
        "\n",
        "for dir_name in output_dirs:\n",
        "    Path(dir_name).mkdir(exist_ok=True)\n",
        "    print(f\"‚úÖ {dir_name}/\")\n",
        "\n",
        "print(\"\\n‚úÖ Dossiers cr√©√©s !\")"
      ],
      "metadata": {
        "id": "7A43iNffT7QW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "visualiser les donn√©es:"
      ],
      "metadata": {
        "id": "P6MGfAuEZOc8"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cU7RBIFmZRK3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cellule 10 : R√©sum√© de l'environnement"
      ],
      "metadata": {
        "id": "hG8WW-rvZIER"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"üìã R√âSUM√â DE L'ENVIRONNEMENT\")\n",
        "print(\"=\"*70 + \"\\n\")\n",
        "\n",
        "summary = {\n",
        "    \"GPU\": torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"None\",\n",
        "    \"CUDA\": torch.version.cuda if torch.cuda.is_available() else \"N/A\",\n",
        "    \"PyTorch\": torch.__version__,\n",
        "    \"Datasets\": {},\n",
        "    \"Projet\": \"CropHealth_Detection_PFE\",\n",
        "    \"Status\": \"‚úÖ Pr√™t pour le training\"\n",
        "}\n",
        "\n",
        "# Compter images\n",
        "for format_name in ['pascal_voc', 'yolo_crop', 'coco_crop']:\n",
        "    train_imgs = Path(f'data/{format_name}/train')\n",
        "    if train_imgs.exists():\n",
        "        if format_name == 'pascal_voc':\n",
        "            count = len(list((train_imgs / 'JPEGImages').glob('*.jpg')))\n",
        "        else:\n",
        "            count = len(list((train_imgs / 'images').glob('*.jpg')))\n",
        "\n",
        "        summary[\"Datasets\"][format_name] = f\"{count} images\"\n",
        "\n",
        "# Afficher\n",
        "print(json.dumps(summary, indent=2, ensure_ascii=False))\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"‚úÖ ENVIRONNEMENT PR√äT !\")\n",
        "print(\"=\"*70)\n",
        "print(\"\\n‚û°Ô∏è  Passez au Notebook 2 : Training\")"
      ],
      "metadata": {
        "id": "D0SZW1c6ZIrp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}