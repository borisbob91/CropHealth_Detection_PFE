# ğŸŒ¾ CropHealth Detection - Workflow Complet Google Colab

**Notebook pour exÃ©cuter l'ensemble du projet CropHealth Detection sur Google Colab**

Copiez-collez les cellules suivantes dans un nouveau notebook Colab.

---

## ğŸ“Œ **Cellule 1 : Configuration GPU**

```python
# VÃ©rifier GPU disponible
import torch

print("="*60)
print("ğŸ”§ GPU Configuration")
print("="*60)

if torch.cuda.is_available():
    print(f"âœ… GPU Available: {torch.cuda.get_device_name(0)}")
    print(f"âœ… CUDA Version: {torch.version.cuda}")
    print(f"âœ… Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB")
else:
    print("âš ï¸  No GPU detected - using CPU")
    print("ğŸ’¡ Go to Runtime > Change runtime type > GPU")

print("="*60)
```

---

## ğŸ“Œ **Cellule 2 : Cloner le repository**

```python
# Cloner le projet depuis GitHub
!git clone https://github.com/borisbob91/CropHealth_Detection_PFE.git
%cd CropHealth_Detection_PFE

# VÃ©rifier structure
!ls -la
```

---

## ğŸ“Œ **Cellule 3 : Installer les dÃ©pendances**

```python
# Installation des dÃ©pendances
print("ğŸ“¦ Installing dependencies...")

!pip install -q torch torchvision torchmetrics
!pip install -q albumentations ultralytics
!pip install -q effdet timm tensorboard
!pip install -q pycocotools scikit-learn
!pip install -q thop torchinfo matplotlib seaborn

print("âœ… Dependencies installed!")

# VÃ©rifier installations
import torch
import torchvision
import ultralytics
print(f"\nâœ… PyTorch: {torch.__version__}")
print(f"âœ… TorchVision: {torchvision.__version__}")
print(f"âœ… Ultralytics: {ultralytics.__version__}")
```

---

## ğŸ“Œ **Cellule 4 : Monter Google Drive (optionnel)**

```python
# Monter Google Drive pour accÃ©der au dataset
from google.colab import drive
drive.mount('/content/drive')

# CrÃ©er lien symbolique vers dataset dans Drive
# Adapter le chemin selon votre structure Drive
!ln -s /content/drive/MyDrive/CropHealth_Data /content/CropHealth_Detection_PFE/data

print("âœ… Google Drive mounted!")
print("ğŸ“ Dataset path: /content/CropHealth_Detection_PFE/data")
```

---

## ğŸ“Œ **Cellule 5 : Uploader dataset (alternative)**

```python
# Si dataset pas dans Drive, uploader ZIP
from google.colab import files
import zipfile

print("ğŸ“¤ Upload your dataset ZIP file...")
uploaded = files.upload()

# DÃ©compresser
for filename in uploaded.keys():
    print(f"ğŸ“¦ Extracting {filename}...")
    with zipfile.ZipFile(filename, 'r') as zip_ref:
        zip_ref.extractall('data/')
    
print("âœ… Dataset extracted to data/")

# VÃ©rifier structure
!tree data/ -L 2 -d
```

---

## ğŸ“Œ **Cellule 6 : VÃ©rifier structure dataset**

```python
# VÃ©rifier que le dataset est bien structurÃ©
import os
from pathlib import Path

data_root = Path('data/yolo_crop')

print("="*60)
print("ğŸ“ Dataset Structure Check")
print("="*60)

required_paths = [
    data_root / 'train' / 'images',
    data_root / 'train' / 'labels',
    data_root / 'val' / 'images',
    data_root / 'val' / 'labels',
]

for path in required_paths:
    if path.exists():
        count = len(list(path.glob('*')))
        print(f"âœ… {path.relative_to(data_root)}: {count} files")
    else:
        print(f"âŒ {path.relative_to(data_root)}: NOT FOUND")

print("="*60)
```

---

## ğŸ“Œ **Cellule 7 : Training SSD MobileNetV3**

```python
# Train SSD
!python train.py \
    --model ssd \
    --data data/yolo_crop \
    --device cuda

print("\nâœ… SSD training complete!")
print("ğŸ“ Results in: runs/CropHealth_SSD_*/")
```

---

## ğŸ“Œ **Cellule 8 : Training YOLOv8n**

```python
# Train YOLOv8n
!python train_yolo.py \
    --data data/yolo_crop/data.yaml \
    --device 0 \
    --cache

print("\nâœ… YOLOv8n training complete!")
print("ğŸ“ Results in: runs/CropHealth_YOLOv8n_*/")
```

---

## ğŸ“Œ **Cellule 9 : Training EfficientDet-D0**

```python
# Convertir YOLO â†’ COCO
!python utils/yolo2coco.py \
    --yolo-root data/yolo_crop \
    --output data/coco_crop

# Train EfficientDet
!python train.py \
    --model efficientdet \
    --data data/coco_crop \
    --device cuda

print("\nâœ… EfficientDet-D0 training complete!")
print("ğŸ“ Results in: runs/CropHealth_EfficientDet_*/")
```

---

## ğŸ“Œ **Cellule 10 : Training Faster R-CNN**

```python
# Train Faster R-CNN ResNet50
!python train.py \
    --model fasterrcnn \
    --data data/yolo_crop \
    --device cuda

print("\nâœ… Faster R-CNN training complete!")
print("ğŸ“ Results in: runs/CropHealth_FasterRCNN_*/")
```

---

## ğŸ“Œ **Cellule 11 : Training Faster R-CNN Light**

```python
# Train Faster R-CNN MobileNetV3 (light)
!python train.py \
    --model fasterrcnn_light \
    --data data/yolo_crop \
    --device cuda

print("\nâœ… Faster R-CNN Light training complete!")
print("ğŸ“ Results in: runs/CropHealth_FasterRCNN_light_*/")
```

---

## ğŸ“Œ **Cellule 12 : TensorBoard (pendant training)**

```python
# Lancer TensorBoard pour visualiser mÃ©triques
%load_ext tensorboard
%tensorboard --logdir runs/

# Ou spÃ©cifier un run particulier
# %tensorboard --logdir runs/CropHealth_SSD_1117_1430/
```

---

## ğŸ“Œ **Cellule 13 : InfÃ©rence SSD**

```python
# Trouver le dernier checkpoint SSD
import glob
ssd_checkpoints = sorted(glob.glob('runs/CropHealth_SSD_*/best.pt'))
latest_ssd = ssd_checkpoints[-1] if ssd_checkpoints else None

if latest_ssd:
    print(f"ğŸ“¦ Using checkpoint: {latest_ssd}")
    
    # InfÃ©rence avec mÃ©triques
    !python predict.py \
        --model ssd \
        --checkpoint {latest_ssd} \
        --input data/yolo_crop/val/images \
        --val-data data/yolo_crop \
        --output predictions/ssd \
        --conf 0.5
    
    print("\nâœ… Predictions saved to predictions/ssd/")
else:
    print("âŒ No SSD checkpoint found. Train the model first.")
```

---

## ğŸ“Œ **Cellule 14 : InfÃ©rence YOLOv8n**

```python
# Trouver le dernier checkpoint YOLOv8n
yolo_checkpoints = sorted(glob.glob('runs/CropHealth_YOLOv8n_*/weights/best.pt'))
latest_yolo = yolo_checkpoints[-1] if yolo_checkpoints else None

if latest_yolo:
    print(f"ğŸ“¦ Using checkpoint: {latest_yolo}")
    
    # InfÃ©rence
    !python yolo_predict.py \
        --checkpoint {latest_yolo} \
        --input data/yolo_crop/val/images \
        --data-yaml data/yolo_crop/data.yaml \
        --output predictions/yolo \
        --conf 0.5
    
    print("\nâœ… Predictions saved to predictions/yolo/")
else:
    print("âŒ No YOLOv8n checkpoint found. Train the model first.")
```

---

## ğŸ“Œ **Cellule 15 : Ã‰valuation multi-modÃ¨les**

```python
# Ã‰valuation comparative de tous les modÃ¨les
!python evaluate_models.py \
    --checkpoints \
        ssd:runs/CropHealth_SSD_*/best.pt \
        yolov8n:runs/CropHealth_YOLOv8n_*/weights/best.pt \
        efficientdet:runs/CropHealth_EfficientDet_*/best.pt \
        fasterrcnn:runs/CropHealth_FasterRCNN_*/best.pt \
        fasterrcnn_light:runs/CropHealth_FasterRCNN_light_*/best.pt \
    --val-data data/yolo_crop \
    --output evaluation_results \
    --device cuda

print("\nâœ… Evaluation complete!")
print("ğŸ“Š Results in: evaluation_results/")
```

---

## ğŸ“Œ **Cellule 16 : Visualiser rÃ©sultats Ã©valuation**

```python
# Afficher les plots gÃ©nÃ©rÃ©s
from IPython.display import Image, display
import glob

print("="*60)
print("ğŸ“Š EVALUATION RESULTS")
print("="*60)

# mAP@50 comparison
if Path('evaluation_results/map50_comparison.png').exists():
    print("\nğŸ“ˆ mAP@50 Global Comparison:")
    display(Image('evaluation_results/map50_comparison.png'))

# AP@50 per class
if Path('evaluation_results/ap50_per_class_comparison.png').exists():
    print("\nğŸ“ˆ AP@50 per Class:")
    display(Image('evaluation_results/ap50_per_class_comparison.png'))

# F1-Score per class
if Path('evaluation_results/f1_per_class_comparison.png').exists():
    print("\nğŸ“ˆ F1-Score per Class:")
    display(Image('evaluation_results/f1_per_class_comparison.png'))

# Confusion matrices
cm_files = sorted(glob.glob('evaluation_results/confusion_matrix_*.png'))
for cm_file in cm_files[:3]:  # Afficher 3 premiers
    model_name = Path(cm_file).stem.replace('confusion_matrix_', '')
    print(f"\nğŸ“Š Confusion Matrix - {model_name}:")
    display(Image(cm_file))
```

---

## ğŸ“Œ **Cellule 17 : Afficher CSV mÃ©triques**

```python
# Afficher tableaux CSV
import pandas as pd

print("="*60)
print("ğŸ“Š METRICS SUMMARY")
print("="*60)

# Global metrics
if Path('evaluation_results/global_metrics.csv').exists():
    print("\nğŸ“ˆ Global Metrics (mAP@50 + F1-Score):")
    df_global = pd.read_csv('evaluation_results/global_metrics.csv')
    display(df_global)

# AP@50 per class
if Path('evaluation_results/ap50_per_class.csv').exists():
    print("\nğŸ“ˆ AP@50 per Class:")
    df_ap = pd.read_csv('evaluation_results/ap50_per_class.csv')
    display(df_ap)

# F1 per class
if Path('evaluation_results/f1_per_class.csv').exists():
    print("\nğŸ“ˆ F1-Score per Class:")
    df_f1 = pd.read_csv('evaluation_results/f1_per_class.csv')
    display(df_f1.head(20))  # PremiÃ¨res lignes
```

---

## ğŸ“Œ **Cellule 18 : Export ONNX**

```python
# Export best model to ONNX
best_checkpoint = 'runs/CropHealth_SSD_*/best.pt'  # Adapter selon meilleur modÃ¨le

!python export/export_models.py \
    --model ssd \
    --checkpoint {best_checkpoint} \
    --format onnx \
    --output exports/ssd

print("\nâœ… ONNX export complete!")
print("ğŸ“¦ Model: exports/ssd/CropHealth_SSD.onnx")
```

---

## ğŸ“Œ **Cellule 19 : Export TFLite INT8**

```python
# Export to TFLite INT8 for mobile deployment
!python export/export_models.py \
    --model ssd \
    --checkpoint {best_checkpoint} \
    --format tflite \
    --quantize int8 \
    --calibration-data data/yolo_crop/train/images \
    --output exports/ssd

print("\nâœ… TFLite INT8 export complete!")
print("ğŸ“¦ Model: exports/ssd/CropHealth_SSD_int8.tflite")
```

---

## ğŸ“Œ **Cellule 20 : Benchmark exports**

```python
# Benchmark PyTorch vs ONNX
!python export/benchmark_exports.py \
    --model ssd \
    --pytorch {best_checkpoint} \
    --onnx exports/ssd/CropHealth_SSD.onnx \
    --tflite exports/ssd/CropHealth_SSD_int8.tflite \
    --runs 100 \
    --output benchmark_ssd.csv

# Afficher rÃ©sultats
print("\nğŸ“Š Benchmark Results:")
df_bench = pd.read_csv('benchmark_ssd.csv')
display(df_bench)
```

---

## ğŸ“Œ **Cellule 21 : Visualiser prÃ©dictions**

```python
# Afficher quelques prÃ©dictions
from IPython.display import Image as IPImage, display
import random

pred_images = list(Path('predictions/ssd/').glob('*.jpg'))
random.shuffle(pred_images)

print("="*60)
print("ğŸ–¼ï¸  SAMPLE PREDICTIONS")
print("="*60)

for img_path in pred_images[:5]:  # 5 images alÃ©atoires
    print(f"\nğŸ“· {img_path.name}:")
    display(IPImage(filename=str(img_path), width=600))
```

---

## ğŸ“Œ **Cellule 22 : TÃ©lÃ©charger rÃ©sultats**

```python
# Zipper tous les rÃ©sultats pour tÃ©lÃ©chargement
import shutil

# CrÃ©er archive
print("ğŸ“¦ Creating results archive...")

shutil.make_archive('crophealth_results', 'zip', 'runs')
shutil.make_archive('crophealth_predictions', 'zip', 'predictions')
shutil.make_archive('crophealth_evaluation', 'zip', 'evaluation_results')
shutil.make_archive('crophealth_exports', 'zip', 'exports')

print("âœ… Archives created!")

# TÃ©lÃ©charger
from google.colab import files

print("\nğŸ“¥ Downloading archives...")
files.download('crophealth_results.zip')
files.download('crophealth_predictions.zip')
files.download('crophealth_evaluation.zip')
files.download('crophealth_exports.zip')

print("\nâœ… Download complete!")
```

---

## ğŸ“Œ **Cellule 23 : Sauvegarder dans Google Drive**

```python
# Copier rÃ©sultats vers Google Drive
import shutil
from datetime import datetime

timestamp = datetime.now().strftime('%Y%m%d_%H%M')
drive_backup = f'/content/drive/MyDrive/CropHealth_Backup_{timestamp}'

print(f"ğŸ’¾ Backing up to: {drive_backup}")

# CrÃ©er dossier
!mkdir -p {drive_backup}

# Copier
shutil.copytree('runs', f'{drive_backup}/runs', dirs_exist_ok=True)
shutil.copytree('predictions', f'{drive_backup}/predictions', dirs_exist_ok=True)
shutil.copytree('evaluation_results', f'{drive_backup}/evaluation_results', dirs_exist_ok=True)
shutil.copytree('exports', f'{drive_backup}/exports', dirs_exist_ok=True)

print(f"\nâœ… Backup complete!")
print(f"ğŸ“ Location: {drive_backup}")
```

---

## ğŸ“Œ **Cellule 24 : RÃ©sumÃ© final**

```python
# Afficher rÃ©sumÃ© complet
import json

print("="*60)
print("ğŸŒ¾ CROPHEALTH DETECTION - FINAL SUMMARY")
print("="*60)

# Compter checkpoints
models_trained = {
    'SSD': len(glob.glob('runs/CropHealth_SSD_*/best.pt')),
    'YOLOv8n': len(glob.glob('runs/CropHealth_YOLOv8n_*/weights/best.pt')),
    'EfficientDet': len(glob.glob('runs/CropHealth_EfficientDet_*/best.pt')),
    'Faster R-CNN': len(glob.glob('runs/CropHealth_FasterRCNN_*/best.pt')),
    'Faster R-CNN Light': len(glob.glob('runs/CropHealth_FasterRCNN_light_*/best.pt')),
}

print("\nğŸ“Š Models Trained:")
for model, count in models_trained.items():
    status = "âœ…" if count > 0 else "âŒ"
    print(f"  {status} {model}: {count} checkpoint(s)")

# Exports
print("\nğŸ“¦ Models Exported:")
export_formats = ['onnx', 'tflite', 'engine']
for fmt in export_formats:
    count = len(glob.glob(f'exports/**/*.{fmt}', recursive=True))
    status = "âœ…" if count > 0 else "âŒ"
    print(f"  {status} {fmt.upper()}: {count} file(s)")

# Ã‰valuations
print("\nğŸ“ˆ Evaluation Results:")
eval_files = [
    'global_metrics.csv',
    'ap50_per_class.csv',
    'f1_per_class.csv',
    'map50_comparison.png'
]
for file in eval_files:
    path = Path('evaluation_results') / file
    status = "âœ…" if path.exists() else "âŒ"
    print(f"  {status} {file}")

print("\n" + "="*60)
print("âœ… Workflow Complete!")
print("="*60)
```

---

## ğŸ¯ **Instructions d'utilisation**

1. **Ouvrir Google Colab** : https://colab.research.google.com/
2. **CrÃ©er un nouveau notebook**
3. **Copier-coller les cellules** dans l'ordre
4. **ExÃ©cuter sÃ©quentiellement** (Shift + Enter)
5. **Attendre la fin de chaque Ã©tape** avant de passer Ã  la suivante

---

## âš¡ **Raccourcis Colab**

| Action | Raccourci |
|--------|-----------|
| ExÃ©cuter cellule | `Ctrl/Cmd + Enter` |
| ExÃ©cuter et passer Ã  suivante | `Shift + Enter` |
| Ajouter cellule | `Ctrl/Cmd + M B` |
| ArrÃªter exÃ©cution | `Ctrl/Cmd + M I` |
| Mode commande | `Esc` |

---

## ğŸ• **Temps estimÃ©**

| Ã‰tape | DurÃ©e (GPU T4) |
|-------|----------------|
| Installation dÃ©pendances | 2-3 min |
| Upload dataset | 5-10 min |
| Training SSD | 30-45 min |
| Training YOLOv8n | 40-60 min |
| Training EfficientDet | 50-70 min |
| Training Faster R-CNN | 60-90 min |
| Ã‰valuation multi-modÃ¨les | 10-15 min |
| Export modÃ¨les | 5-10 min |
| **Total** | **~4-6 heures** |

---

## ğŸ’¡ **Astuces Colab**

1. **Garder session active** : ExÃ©cuter cellule vide pÃ©riodiquement
2. **Sauvegarder frÃ©quemment** : Copier vers Drive toutes les heures
3. **Limites GPU gratuit** : 12h max, redÃ©marre aprÃ¨s
4. **Colab Pro** : GPU plus puissant + 24h runtime

---

## ğŸ”— **Liens utiles**

- **Repo GitHub** : https://github.com/borisbob91/CropHealth_Detection_PFE
- **Documentation PyTorch** : https://pytorch.org/docs/
- **Ultralytics Docs** : https://docs.ultralytics.com/
- **TensorBoard** : Accessible dans interface Colab

---

<p align="center">
  <strong>ğŸŒ¾ Workflow Colab complet ! Bon training ! ğŸš€</strong>
</p>