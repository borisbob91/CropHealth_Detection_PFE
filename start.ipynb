{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1HJos5pZqXM1qHkuZeTuF3DCtbxPU4QIM",
      "authorship_tag": "ABX9TyPyHj83TKghEl5yG0jstAbP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/borisbob91/CropHealth_Detection_PFE/blob/main/start.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üåæ CropHealth Detection - Workflow Complet Google Colab"
      ],
      "metadata": {
        "id": "rsOPTiNl9EhG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notebook pour ex√©cuter l'ensemble du projet CropHealth Detection sur Google Colab"
      ],
      "metadata": {
        "id": "w0D9R3Rg9BzW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  Configuration GPU"
      ],
      "metadata": {
        "id": "VXJfPNbp9CvQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "AGnsLXMe-AI9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# V√©rifier GPU disponible\n",
        "import torch\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"üîß GPU Configuration\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"‚úÖ GPU Available: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"‚úÖ CUDA Version: {torch.version.cuda}\")\n",
        "    print(f\"‚úÖ Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è  No GPU detected - using CPU\")\n",
        "    print(\"üí° Go to Runtime > Change runtime type > GPU\")\n",
        "\n",
        "print(\"=\"*60)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gFnvC3aG-BNe",
        "outputId": "3a26412b-ba34-4f87-9dfa-67d17a0d7f1b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "üîß GPU Configuration\n",
            "============================================================\n",
            "‚úÖ GPU Available: Tesla T4\n",
            "‚úÖ CUDA Version: 12.6\n",
            "‚úÖ Memory: 15.8 GB\n",
            "============================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cloner le repository"
      ],
      "metadata": {
        "id": "X69S7BeG-Qhc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cloner le projet depuis GitHub\n",
        "!git clone https://github.com/borisbob91/CropHealth_Detection_PFE.git\n",
        "%cd CropHealth_Detection_PFE\n",
        "\n",
        "# V√©rifier structure\n",
        "!ls -la"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GbN7A5VC-YTz",
        "outputId": "bf8a9c47-e02c-4382-c409-37d6da5e0aca"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'CropHealth_Detection_PFE'...\n",
            "remote: Enumerating objects: 13, done.\u001b[K\n",
            "remote: Counting objects: 100% (13/13), done.\u001b[K\n",
            "remote: Compressing objects: 100% (11/11), done.\u001b[K\n",
            "remote: Total 13 (delta 3), reused 9 (delta 2), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (13/13), done.\n",
            "Resolving deltas: 100% (3/3), done.\n",
            "/content/CropHealth_Detection_PFE\n",
            "total 32\n",
            "drwxr-xr-x 4 root root 4096 Nov 17 04:01 .\n",
            "drwxr-xr-x 1 root root 4096 Nov 17 04:01 ..\n",
            "drwxr-xr-x 8 root root 4096 Nov 17 04:01 .git\n",
            "-rw-r--r-- 1 root root   66 Nov 17 04:01 .gitattributes\n",
            "drwxr-xr-x 2 root root 4096 Nov 17 04:01 .idea\n",
            "-rw-r--r-- 1 root root 1074 Nov 17 04:01 LICENSE\n",
            "-rw-r--r-- 1 root root   50 Nov 17 04:01 README.md\n",
            "-rw-r--r-- 1 root root 1227 Nov 17 04:01 starter.ipynb\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "138d9e2c",
        "outputId": "00dc75cc-f034-4d3d-b9f6-ef4ab93ce34d"
      },
      "source": [
        "pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118 # for CUDA 11.8. Adjust 'cu118' based on your CUDA version or remove for CPU only."
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (0.23.0+cu126)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision) (11.3.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Installer les d√©pendances"
      ],
      "metadata": {
        "id": "AzEskzWH-gqU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mise √† jour de pip et setuptools\n",
        "print(\"üîÑ Updating pip and setuptools...\")\n",
        "!pip install -U pip setuptools\n",
        "\n",
        "# Installation des d√©pendances principales (core)\n",
        "print(\"üì¶ Installing core dependencies...\")\n",
        "!pip install -q torch torchvision torchmetrics\n",
        "!pip install -q albumentations ultralytics\n",
        "!pip install -q effdet timm tensorboard\n",
        "!pip install -q pycocotools scikit-learn\n",
        "!pip install -q thop torchinfo matplotlib seaborn\n",
        "\n",
        "# Installation des d√©pendances de d√©ploiement (deploy)\n",
        "print(\"üì¶ Installing deploy dependencies (excluding problematic CUDA-specific ones for now)...\")\n",
        "!pip install -q onnx\n",
        "!pip install -q onnxruntime\n",
        "!pip install -q onnxruntime-gpu  # Pour GPU\n",
        "!pip install -q tensorflow  # Pour TFLite\n",
        "!pip install -q onnx-tf  # Pour ONNX ‚Üí TF\n",
        "!pip install -q coremltools  # Pour CoreML\n",
        "\n",
        "# Installation s√©par√©e d'onnx-simplifier\n",
        "print(\"üì¶ Installing onnx-simplifier separately...\")\n",
        "!pip install -q onnx-simplifier\n",
        "\n",
        "print(\"‚úÖ Dependencies installed!\")\n",
        "\n",
        "# V√©rifier installations\n",
        "import torch\n",
        "import torchvision\n",
        "import ultralytics\n",
        "print(f\"\\n‚úÖ PyTorch: {torch.__version__}\")\n",
        "print(f\"‚úÖ TorchVision: {torchvision.__version__}\")\n",
        "print(f\"‚úÖ Ultralytics: {ultralytics.__version__}\")\n",
        "\n",
        "# Note sur les conflits CUDA:\n",
        "# Les messages d'erreur pr√©c√©dents indiquent des conflits avec 'cuda-toolkit' (ex: cuml-cu12 n√©cessite 12.*, mais 13.0.1 est trouv√©).\n",
        "# Les packages 'nvidia-tensorrt' et 'pycuda' sont souvent √† l'origine de ces conflits de version de CUDA dans les environnements Colab.\n",
        "# Ils ont √©t√© temporairement exclus de l'installation pour permettre aux autres d√©pendances de s'installer.\n",
        "# Si vous avez besoin de TensorRT ou de PyCUDA, il faudra les installer avec des versions sp√©cifiques compatibles avec votre environnement CUDA."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ymjzRKR-oNM",
        "outputId": "b57f9d3a-d798-44d9-ca00-457ace744519"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîÑ Updating pip and setuptools...\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.10/dist-packages (25.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (80.9.0)\n",
            "üì¶ Installing core dependencies...\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for antlr4-python3-runtime (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "üì¶ Installing deploy dependencies (excluding problematic CUDA-specific ones for now)...\n",
            "üì¶ Installing onnx-simplifier separately...\n",
            "‚úÖ Dependencies installed!\n",
            "\n",
            "‚úÖ PyTorch: 2.8.0+cu126\n",
            "‚úÖ TorchVision: 0.23.0+cu126\n",
            "‚úÖ Ultralytics: 8.3.228\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "73c3e775"
      },
      "source": [
        "### Installer Python 3.10 et configurer un environnement virtuel\n",
        "\n",
        "Nous allons d'abord installer Python 3.10, puis cr√©er un environnement virtuel (`venv`) avec cette version."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "7ac8f214",
        "outputId": "e64662b5-276a-467e-b3aa-18f37121e180"
      },
      "source": [
        "# Mettre √† jour la liste des paquets et installer Python 3.10\n",
        "!sudo apt-get update -y\n",
        "!sudo apt-get install python3.10 -y\n",
        "\n",
        "# Installer pip pour Python 3.10\n",
        "!sudo apt-get install python3.10-distutils -y\n",
        "!curl https://bootstrap.pypa.io/get-pip.py | python3.10\n",
        "\n",
        "# V√©rifier la version de Python 3.10 install√©e\n",
        "!python3.10 --version"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rGet:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,632 B]\n",
            "\r0% [Connecting to archive.ubuntu.com (185.125.190.83)] [Waiting for headers] [1\r                                                                               \rGet:2 https://cli.github.com/packages stable InRelease [3,917 B]\n",
            "\r0% [Connecting to archive.ubuntu.com (185.125.190.83)] [Waiting for headers] [1\r0% [Connecting to archive.ubuntu.com (185.125.190.83)] [Waiting for headers] [1\r                                                                               \rGet:3 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Get:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:6 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
            "Get:7 https://cli.github.com/packages stable/main amd64 Packages [343 B]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Hit:9 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Get:10 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [2,143 kB]\n",
            "Hit:11 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:12 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:13 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Get:14 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [9,457 kB]\n",
            "Get:15 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,827 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [3,861 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,595 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [6,181 kB]\n",
            "Fetched 26.5 MB in 3s (7,705 kB/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "python3.10 is already the newest version (3.10.12-1~22.04.11).\n",
            "python3.10 set to manually installed.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 49 not upgraded.\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "Note, selecting 'python3-distutils' instead of 'python3.10-distutils'\n",
            "python3-distutils is already the newest version (3.10.8-1~22.04).\n",
            "python3-distutils set to manually installed.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 49 not upgraded.\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 2131k  100 2131k    0     0  6721k      0 --:--:-- --:--:-- --:--:-- 6723k\n",
            "Collecting pip\n",
            "  Using cached pip-25.3-py3-none-any.whl.metadata (4.7 kB)\n",
            "Collecting setuptools\n",
            "  Using cached setuptools-80.9.0-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting wheel\n",
            "  Using cached wheel-0.45.1-py3-none-any.whl.metadata (2.3 kB)\n",
            "Using cached pip-25.3-py3-none-any.whl (1.8 MB)\n",
            "Using cached setuptools-80.9.0-py3-none-any.whl (1.2 MB)\n",
            "Using cached wheel-0.45.1-py3-none-any.whl (72 kB)\n",
            "Installing collected packages: wheel, setuptools, pip\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m3/3\u001b[0m [pip]\n",
            "\u001b[1A\u001b[2KSuccessfully installed pip-25.3 setuptools-80.9.0 wheel-0.45.1\n",
            "Python 3.10.12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "694d83e2"
      },
      "source": [
        "Maintenant que Python 3.10 est install√©, nous allons cr√©er un environnement virtuel nomm√© `myenv_py310`. Cet environnement isolera les d√©pendances de votre projet, et vous pourrez utiliser Python 3.10 √† l'int√©rieur."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "db5ce484",
        "outputId": "8cf6f71a-7aa9-4fb3-eb52-efbf69cb925d"
      },
      "source": [
        "# Installer le package python3.10-venv n√©cessaire pour la cr√©ation d'environnements virtuels\n",
        "!apt-get install python3.10-venv -y\n",
        "\n",
        "# Cr√©er un environnement virtuel avec Python 3.10\n",
        "!python3.10 -m venv myenv_py310\n",
        "\n",
        "# V√©rifier que le pip de l'environnement virtuel fonctionne\n",
        "!./myenv_py310/bin/pip --version\n",
        "\n",
        "print(\"Environnement virtuel 'myenv_py310' cr√©√© avec Python 3.10.\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The virtual environment was not created successfully because ensurepip is not\n",
            "available.  On Debian/Ubuntu systems, you need to install the python3-venv\n",
            "package using the following command.\n",
            "\n",
            "    apt install python3.10-venv\n",
            "\n",
            "You may need to use sudo with that command.  After installing the python3-venv\n",
            "package, recreate your virtual environment.\n",
            "\n",
            "Failing command: /content/myenv_py310/bin/python3.10\n",
            "\n",
            "/bin/bash: line 1: ./myenv_py310/bin/pip: No such file or directory\n",
            "Environnement virtuel 'myenv_py310' cr√©√© avec Python 3.10.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ca86824f"
      },
      "source": [
        "### Comment utiliser l'environnement virtuel Python 3.10\n",
        "\n",
        "Dans Google Colab, l'activation d'un environnement virtuel n'est pas persistante entre les cellules si vous utilisez la syntaxe `!`. Pour ex√©cuter des commandes dans votre nouvel environnement Python 3.10, vous devrez sp√©cifier le chemin complet vers l'ex√©cutable Python ou pip √† l'int√©rieur de cet environnement.\n",
        "\n",
        "Par exemple :\n",
        "\n",
        "-   Pour installer une biblioth√®que :\n",
        "    `!./myenv_py310/bin/pip install nom_de_la_bibliotheque`\n",
        "\n",
        "-   Pour ex√©cuter un script Python avec Python 3.10 :\n",
        "    `!./myenv_py310/bin/python votre_script.py`\n",
        "\n",
        "-   Pour d√©marrer un notebook avec le kernel de votre environnement virtuel (n√©cessite une configuration avanc√©e et n'est pas toujours simple dans Colab), ou pour ex√©cuter le code d'une cellule avec Python 3.10, vous devrez pr√©fixer vos commandes.\n",
        "\n",
        "Je vais maintenant modifier la cellule d'installation de vos d√©pendances pour qu'elle utilise cet environnement Python 3.10."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9808d765"
      },
      "source": [
        "Si vous n'avez pas de GPU compatible CUDA ou si vous pr√©f√©rez une installation uniquement CPU, vous pouvez utiliser:\n",
        "\n",
        "```python\n",
        "pip install torch torchvision torchaudio\n",
        "```\n",
        "\n",
        "Apr√®s l'installation, vous pouvez v√©rifier si PyTorch et CUDA sont correctement install√©s avec le code suivant:"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "mzHeaLAa93KB"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ba43979d",
        "outputId": "53f8ba31-51d0-426b-d254-96c6a9fa486d"
      },
      "source": [
        "import torch\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"CUDA version: {torch.version.cuda}\")\n",
        "    print(f\"Current CUDA device: {torch.cuda.current_device()}\")\n",
        "    print(f\"Name of current CUDA device: {torch.cuda.get_device_name(torch.cuda.current_device())}\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch version: 2.8.0+cu126\n",
            "CUDA available: True\n",
            "CUDA version: 12.6\n",
            "Current CUDA device: 0\n",
            "Name of current CUDA device: Tesla T4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e323d9ab"
      },
      "source": [
        "pip install requests"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0eba0d4b"
      },
      "source": [
        "If you want to install a specific version, you can specify it like this:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "13a52b4d"
      },
      "source": [
        "pip install requests==2.28.1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Monter Google Drive (optionnel)"
      ],
      "metadata": {
        "id": "dozVzhmcHBPX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Monter Google Drive pour acc√©der au dataset\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Cr√©er lien symbolique vers dataset dans Drive\n",
        "# Adapter le chemin selon votre structure Drive\n",
        "!ln -s /content/drive/MyDrive/CropHealth /content/CropHealth_Detection_PFE/data\n",
        "\n",
        "print(\"‚úÖ Google Drive mounted!\")\n",
        "print(\"üìÅ Dataset path: /content/CropHealth_Detection_PFE/data\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CVZLIFrOHE_m",
        "outputId": "f4b30964-44e6-4ae9-f4bb-cde82da4c51e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "‚úÖ Google Drive mounted!\n",
            "üìÅ Dataset path: /content/CropHealth_Detection_PFE/data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " ## Uploader dataset (alternative)"
      ],
      "metadata": {
        "id": "KV5l1ce9Ilg_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Si dataset pas dans Drive, uploader ZIP\n",
        "from google.colab import files\n",
        "import zipfile\n",
        "\n",
        "print(\"üì§ Upload your dataset ZIP file...\")\n",
        "uploaded = files.upload()\n",
        "\n",
        "# D√©compresser\n",
        "for filename in uploaded.keys():\n",
        "    print(f\"üì¶ Extracting {filename}...\")\n",
        "    with zipfile.ZipFile(filename, 'r') as zip_ref:\n",
        "        zip_ref.extractall('data/')\n",
        "\n",
        "print(\"‚úÖ Dataset extracted to data/\")\n",
        "\n",
        "# V√©rifier structure\n",
        "!tree data/ -L 2 -d"
      ],
      "metadata": {
        "id": "U36wACh6IiPP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " Cellule 6 : V√©rifier structure dataset"
      ],
      "metadata": {
        "id": "njLTcYIFI7p8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# V√©rifier que le dataset est bien structur√©\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "data_root = Path('data/yolo_crop')\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"üìÅ Dataset Structure Check\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "required_paths = [\n",
        "    data_root / 'train' / 'images',\n",
        "    data_root / 'train' / 'labels',\n",
        "    data_root / 'val' / 'images',\n",
        "    data_root / 'val' / 'labels',\n",
        "]\n",
        "\n",
        "for path in required_paths:\n",
        "    if path.exists():\n",
        "        count = len(list(path.glob('*')))\n",
        "        print(f\"‚úÖ {path.relative_to(data_root)}: {count} files\")\n",
        "    else:\n",
        "        print(f\"‚ùå {path.relative_to(data_root)}: NOT FOUND\")\n",
        "\n",
        "print(\"=\"*60)"
      ],
      "metadata": {
        "id": "C-fyAg8iJA_y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "üìå Cellule 7 : Training SSD MobileNetV3"
      ],
      "metadata": {
        "id": "jWQxsZMZJD7c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train SSD\n",
        "!python train.py \\\n",
        "    --model ssd \\\n",
        "    --data data/yolo_crop \\\n",
        "    --device cuda\n",
        "\n",
        "print(\"\\n‚úÖ SSD training complete!\")\n",
        "print(\"üìÅ Results in: runs/CropHealth_SSD_*/\")"
      ],
      "metadata": {
        "id": "pKw7vZSqJWhX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cellule 8 : Training YOLOv8n"
      ],
      "metadata": {
        "id": "sH7nVkPFJawl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train YOLOv8n\n",
        "!python train_yolo.py \\\n",
        "    --data data/yolo_crop/data.yaml \\\n",
        "    --device 0 \\\n",
        "    --cache\n",
        "\n",
        "print(\"\\n‚úÖ YOLOv8n training complete!\")\n",
        "print(\"üìÅ Results in: runs/CropHealth_YOLOv8n_*/\")"
      ],
      "metadata": {
        "id": "syVQJvp3JeEq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cellule 9 : Training EfficientDet-D0"
      ],
      "metadata": {
        "id": "4CASK5agJgWB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convertir YOLO ‚Üí COCO\n",
        "!python utils/yolo2coco.py \\\n",
        "    --yolo-root data/yolo_crop \\\n",
        "    --output data/coco_crop\n",
        "\n",
        "# Train EfficientDet\n",
        "!python train.py \\\n",
        "    --model efficientdet \\\n",
        "    --data data/coco_crop \\\n",
        "    --device cuda\n",
        "\n",
        "print(\"\\n‚úÖ EfficientDet-D0 training complete!\")\n",
        "print(\"üìÅ Results in: runs/CropHealth_EfficientDet_*/\")"
      ],
      "metadata": {
        "id": "tBs-p2oNJpp9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cellule 10 : Training Faster R-CNN"
      ],
      "metadata": {
        "id": "64Mee9yWJrl0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train Faster R-CNN ResNet50\n",
        "!python train.py \\\n",
        "    --model fasterrcnn \\\n",
        "    --data data/yolo_crop \\\n",
        "    --device cuda\n",
        "\n",
        "print(\"\\n‚úÖ Faster R-CNN training complete!\")\n",
        "print(\"üìÅ Results in: runs/CropHealth_FasterRCNN_*/\")"
      ],
      "metadata": {
        "id": "iv6a4H9tJ3Yr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cellule 11 : Training Faster R-CNN Light"
      ],
      "metadata": {
        "id": "4CgPpErfKY8r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train Faster R-CNN MobileNetV3 (light)\n",
        "!python train.py \\\n",
        "    --model fasterrcnn_light \\\n",
        "    --data data/yolo_crop \\\n",
        "    --device cuda\n",
        "\n",
        "print(\"\\n‚úÖ Faster R-CNN Light training complete!\")\n",
        "print(\"üìÅ Results in: runs/CropHealth_FasterRCNN_light_*/\")"
      ],
      "metadata": {
        "id": "3y0sc4SmKbzW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cellule 12 : TensorBoard (pendant training)"
      ],
      "metadata": {
        "id": "GuPpXVxLKeLL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Lancer TensorBoard pour visualiser m√©triques\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir runs/\n",
        "\n",
        "# Ou sp√©cifier un run particulier\n",
        "# %tensorboard --logdir runs/CropHealth_SSD_1117_1430/"
      ],
      "metadata": {
        "id": "4OP4PdOEKsgc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " Inf√©rence SSD"
      ],
      "metadata": {
        "id": "EeRym-WgK8jS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Trouver le dernier checkpoint SSD\n",
        "import glob\n",
        "ssd_checkpoints = sorted(glob.glob('runs/CropHealth_SSD_*/best.pt'))\n",
        "latest_ssd = ssd_checkpoints[-1] if ssd_checkpoints else None\n",
        "\n",
        "if latest_ssd:\n",
        "    print(f\"üì¶ Using checkpoint: {latest_ssd}\")\n",
        "\n",
        "    # Inf√©rence avec m√©triques\n",
        "    !python predict.py \\\n",
        "        --model ssd \\\n",
        "        --checkpoint {latest_ssd} \\\n",
        "        --input data/yolo_crop/val/images \\\n",
        "        --val-data data/yolo_crop \\\n",
        "        --output predictions/ssd \\\n",
        "        --conf 0.5\n",
        "\n",
        "    print(\"\\n‚úÖ Predictions saved to predictions/ssd/\")\n",
        "else:\n",
        "    print(\"‚ùå No SSD checkpoint found. Train the model first.\")"
      ],
      "metadata": {
        "id": "4ZXOsQitK_LO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cellule 14 : Inf√©rence YOLOv8n"
      ],
      "metadata": {
        "id": "vqAYugh-LkNc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Trouver le dernier checkpoint YOLOv8n\n",
        "yolo_checkpoints = sorted(glob.glob('runs/CropHealth_YOLOv8n_*/weights/best.pt'))\n",
        "latest_yolo = yolo_checkpoints[-1] if yolo_checkpoints else None\n",
        "\n",
        "if latest_yolo:\n",
        "    print(f\"üì¶ Using checkpoint: {latest_yolo}\")\n",
        "\n",
        "    # Inf√©rence\n",
        "    !python yolo_predict.py \\\n",
        "        --checkpoint {latest_yolo} \\\n",
        "        --input data/yolo_crop/val/images \\\n",
        "        --data-yaml data/yolo_crop/data.yaml \\\n",
        "        --output predictions/yolo \\\n",
        "        --conf 0.5\n",
        "\n",
        "    print(\"\\n‚úÖ Predictions saved to predictions/yolo/\")\n",
        "else:\n",
        "    print(\"‚ùå No YOLOv8n checkpoint found. Train the model first.\")"
      ],
      "metadata": {
        "id": "stx9ymbOLlPz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ": √âvaluation multi-mod√®les"
      ],
      "metadata": {
        "id": "bmdwErxLLoSi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# √âvaluation comparative de tous les mod√®les\n",
        "!python evaluate_models.py \\\n",
        "    --checkpoints \\\n",
        "        ssd:runs/CropHealth_SSD_*/best.pt \\\n",
        "        yolov8n:runs/CropHealth_YOLOv8n_*/weights/best.pt \\\n",
        "        efficientdet:runs/CropHealth_EfficientDet_*/best.pt \\\n",
        "        fasterrcnn:runs/CropHealth_FasterRCNN_*/best.pt \\\n",
        "        fasterrcnn_light:runs/CropHealth_FasterRCNN_light_*/best.pt \\\n",
        "    --val-data data/yolo_crop \\\n",
        "    --output evaluation_results \\\n",
        "    --device cuda\n",
        "\n",
        "print(\"\\n‚úÖ Evaluation complete!\")\n",
        "print(\"üìä Results in: evaluation_results/\")"
      ],
      "metadata": {
        "id": "a5AnaqL5LrqP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cellule 16 : Visualiser r√©sultats √©valuation"
      ],
      "metadata": {
        "id": "zURQNy1YL5Cs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Afficher les plots g√©n√©r√©s\n",
        "from IPython.display import Image, display\n",
        "import glob\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"üìä EVALUATION RESULTS\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# mAP@50 comparison\n",
        "if Path('evaluation_results/map50_comparison.png').exists():\n",
        "    print(\"\\nüìà mAP@50 Global Comparison:\")\n",
        "    display(Image('evaluation_results/map50_comparison.png'))\n",
        "\n",
        "# AP@50 per class\n",
        "if Path('evaluation_results/ap50_per_class_comparison.png').exists():\n",
        "    print(\"\\nüìà AP@50 per Class:\")\n",
        "    display(Image('evaluation_results/ap50_per_class_comparison.png'))\n",
        "\n",
        "# F1-Score per class\n",
        "if Path('evaluation_results/f1_per_class_comparison.png').exists():\n",
        "    print(\"\\nüìà F1-Score per Class:\")\n",
        "    display(Image('evaluation_results/f1_per_class_comparison.png'))\n",
        "\n",
        "# Confusion matrices\n",
        "cm_files = sorted(glob.glob('evaluation_results/confusion_matrix_*.png'))\n",
        "for cm_file in cm_files[:3]:  # Afficher 3 premiers\n",
        "    model_name = Path(cm_file).stem.replace('confusion_matrix_', '')\n",
        "    print(f\"\\nüìä Confusion Matrix - {model_name}:\")\n",
        "    display(Image(cm_file))"
      ],
      "metadata": {
        "id": "SW0gi-pCL6Ff"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cellule 17 : Afficher CSV m√©triques"
      ],
      "metadata": {
        "id": "rV0W007fL-qZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Afficher tableaux CSV\n",
        "import pandas as pd\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"üìä METRICS SUMMARY\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Global metrics\n",
        "if Path('evaluation_results/global_metrics.csv').exists():\n",
        "    print(\"\\nüìà Global Metrics (mAP@50 + F1-Score):\")\n",
        "    df_global = pd.read_csv('evaluation_results/global_metrics.csv')\n",
        "    display(df_global)\n",
        "\n",
        "# AP@50 per class\n",
        "if Path('evaluation_results/ap50_per_class.csv').exists():\n",
        "    print(\"\\nüìà AP@50 per Class:\")\n",
        "    df_ap = pd.read_csv('evaluation_results/ap50_per_class.csv')\n",
        "    display(df_ap)\n",
        "\n",
        "# F1 per class\n",
        "if Path('evaluation_results/f1_per_class.csv').exists():\n",
        "    print(\"\\nüìà F1-Score per Class:\")\n",
        "    df_f1 = pd.read_csv('evaluation_results/f1_per_class.csv')\n",
        "    display(df_f1.head(20))  # Premi√®res lignes"
      ],
      "metadata": {
        "id": "3OHxQcVXMDxM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cellule 18 : Export ONNX"
      ],
      "metadata": {
        "id": "5HDtau6UMGL5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Export best model to ONNX\n",
        "best_checkpoint = 'runs/CropHealth_SSD_*/best.pt'  # Adapter selon meilleur mod√®le\n",
        "\n",
        "!python export/export_models.py \\\n",
        "    --model ssd \\\n",
        "    --checkpoint {best_checkpoint} \\\n",
        "    --format onnx \\\n",
        "    --output exports/ssd\n",
        "\n",
        "print(\"\\n‚úÖ ONNX export complete!\")\n",
        "print(\"üì¶ Model: exports/ssd/CropHealth_SSD.onnx\")"
      ],
      "metadata": {
        "id": "m3qJNAv4MJj6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Export to TFLite INT8 for mobile deployment\n",
        "!python export/export_models.py \\\n",
        "    --model ssd \\\n",
        "    --checkpoint {best_checkpoint} \\\n",
        "    --format tflite \\\n",
        "    --quantize int8 \\\n",
        "    --calibration-data data/yolo_crop/train/images \\\n",
        "    --output exports/ssd\n",
        "\n",
        "print(\"\\n‚úÖ TFLite INT8 export complete!\")\n",
        "print(\"üì¶ Model: exports/ssd/CropHealth_SSD_int8.tflite\")"
      ],
      "metadata": {
        "id": "ZCg8311hMMek"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Benchmark PyTorch vs ONNX\n",
        "!python export/benchmark_exports.py \\\n",
        "    --model ssd \\\n",
        "    --pytorch {best_checkpoint} \\\n",
        "    --onnx exports/ssd/CropHealth_SSD.onnx \\\n",
        "    --tflite exports/ssd/CropHealth_SSD_int8.tflite \\\n",
        "    --runs 100 \\\n",
        "    --output benchmark_ssd.csv\n",
        "\n",
        "# Afficher r√©sultats\n",
        "print(\"\\nüìä Benchmark Results:\")\n",
        "df_bench = pd.read_csv('benchmark_ssd.csv')\n",
        "display(df_bench)"
      ],
      "metadata": {
        "id": "wSMS1QomMPVq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cellule 21 : Visualiser pr√©dictions"
      ],
      "metadata": {
        "id": "F1aWyNZdMVUv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Afficher quelques pr√©dictions\n",
        "from IPython.display import Image as IPImage, display\n",
        "import random\n",
        "\n",
        "pred_images = list(Path('predictions/ssd/').glob('*.jpg'))\n",
        "random.shuffle(pred_images)\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"üñºÔ∏è  SAMPLE PREDICTIONS\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "for img_path in pred_images[:5]:  # 5 images al√©atoires\n",
        "    print(f\"\\nüì∑ {img_path.name}:\")\n",
        "    display(IPImage(filename=str(img_path), width=600))"
      ],
      "metadata": {
        "id": "a-FXNKcIMSUZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cellule 22 : T√©l√©charger r√©sultats"
      ],
      "metadata": {
        "id": "mhbW6ZLFMkw8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Zipper tous les r√©sultats pour t√©l√©chargement\n",
        "import shutil\n",
        "\n",
        "# Cr√©er archive\n",
        "print(\"üì¶ Creating results archive...\")\n",
        "\n",
        "shutil.make_archive('crophealth_results', 'zip', 'runs')\n",
        "shutil.make_archive('crophealth_predictions', 'zip', 'predictions')\n",
        "shutil.make_archive('crophealth_evaluation', 'zip', 'evaluation_results')\n",
        "shutil.make_archive('crophealth_exports', 'zip', 'exports')\n",
        "\n",
        "print(\"‚úÖ Archives created!\")\n",
        "\n",
        "# T√©l√©charger\n",
        "from google.colab import files\n",
        "\n",
        "print(\"\\nüì• Downloading archives...\")\n",
        "files.download('crophealth_results.zip')\n",
        "files.download('crophealth_predictions.zip')\n",
        "files.download('crophealth_evaluation.zip')\n",
        "files.download('crophealth_exports.zip')\n",
        "\n",
        "print(\"\\n‚úÖ Download complete!\")"
      ],
      "metadata": {
        "id": "w7c4EtNoMlf7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " Cellule 23 : Sauvegarder dans Google Drive"
      ],
      "metadata": {
        "id": "xXM_aKxpMuPZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Copier r√©sultats vers Google Drive\n",
        "import shutil\n",
        "from datetime import datetime\n",
        "\n",
        "timestamp = datetime.now().strftime('%Y%m%d_%H%M')\n",
        "drive_backup = f'/content/drive/MyDrive/CropHealth/Backup_{timestamp}'\n",
        "\n",
        "print(f\"üíæ Backing up to: {drive_backup}\")\n",
        "\n",
        "# Cr√©er dossier\n",
        "!mkdir -p {drive_backup}\n",
        "\n",
        "# Copier\n",
        "shutil.copytree('runs', f'{drive_backup}/runs', dirs_exist_ok=True)\n",
        "shutil.copytree('predictions', f'{drive_backup}/predictions', dirs_exist_ok=True)\n",
        "shutil.copytree('evaluation_results', f'{drive_backup}/evaluation_results', dirs_exist_ok=True)\n",
        "shutil.copytree('exports', f'{drive_backup}/exports', dirs_exist_ok=True)\n",
        "\n",
        "print(f\"\\n‚úÖ Backup complete!\")\n",
        "print(f\"üìÅ Location: {drive_backup}\")"
      ],
      "metadata": {
        "id": "KOx8E4T8MxM2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cellule 24 : R√©sum√© final"
      ],
      "metadata": {
        "id": "yVeFfDixNNm6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Afficher r√©sum√© complet\n",
        "import json\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"üåæ CROPHEALTH DETECTION - FINAL SUMMARY\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Compter checkpoints\n",
        "models_trained = {\n",
        "    'SSD': len(glob.glob('runs/CropHealth_SSD_*/best.pt')),\n",
        "    'YOLOv8n': len(glob.glob('runs/CropHealth_YOLOv8n_*/weights/best.pt')),\n",
        "    'EfficientDet': len(glob.glob('runs/CropHealth_EfficientDet_*/best.pt')),\n",
        "    'Faster R-CNN': len(glob.glob('runs/CropHealth_FasterRCNN_*/best.pt')),\n",
        "    'Faster R-CNN Light': len(glob.glob('runs/CropHealth_FasterRCNN_light_*/best.pt')),\n",
        "}\n",
        "\n",
        "print(\"\\nüìä Models Trained:\")\n",
        "for model, count in models_trained.items():\n",
        "    status = \"‚úÖ\" if count > 0 else \"‚ùå\"\n",
        "    print(f\"  {status} {model}: {count} checkpoint(s)\")\n",
        "\n",
        "# Exports\n",
        "print(\"\\nüì¶ Models Exported:\")\n",
        "export_formats = ['onnx', 'tflite', 'engine']\n",
        "for fmt in export_formats:\n",
        "    count = len(glob.glob(f'exports/**/*.{fmt}', recursive=True))\n",
        "    status = \"‚úÖ\" if count > 0 else \"‚ùå\"\n",
        "    print(f\"  {status} {fmt.upper()}: {count} file(s)\")\n",
        "\n",
        "# √âvaluations\n",
        "print(\"\\nüìà Evaluation Results:\")\n",
        "eval_files = [\n",
        "    'global_metrics.csv',\n",
        "    'ap50_per_class.csv',\n",
        "    'f1_per_class.csv',\n",
        "    'map50_comparison.png'\n",
        "]\n",
        "for file in eval_files:\n",
        "    path = Path('evaluation_results') / file\n",
        "    status = \"‚úÖ\" if path.exists() else \"‚ùå\"\n",
        "    print(f\"  {status} {file}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"‚úÖ Workflow Complete!\")\n",
        "print(\"=\"*60)"
      ],
      "metadata": {
        "id": "hQXC-SxLNOqm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}